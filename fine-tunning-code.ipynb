{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66199,"databundleVersionId":7522884,"sourceType":"competition"}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Define directories\ntrain_dir = '/kaggle/input/bttai-nybg-2024/BTTAIxNYBG-train/BTTAIxNYBG-train'\ntest_dir = '/kaggle/input/bttai-nybg-2024/BTTAIxNYBG-test/BTTAIxNYBG-test'\nvalidation_dir = '/kaggle/input/bttai-nybg-2024/BTTAIxNYBG-validation/BTTAIxNYBG-validation'\n\n# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/bttai-nybg-2024/BTTAIxNYBG-train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-nybg-2024/BTTAIxNYBG-test.csv')\nvalidate_df = pd.read_csv('/kaggle/input/bttai-nybg-2024/BTTAIxNYBG-validation.csv')\n\n# Data augmentation configuration for training\ntrain_datagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    rescale=1./255\n)\n\n# Note: No augmentation for validation and test data, only rescaling\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Convert dataframe to a format suitable for the model training\ndef df_to_dataset(dataframe, datagen, directory, batch_size=32):\n    return datagen.flow_from_dataframe(\n        dataframe=dataframe,\n        directory=directory,\n        x_col='imageFile',  # Column in dataframe that contains the filenames\n        y_col='classLabel',  # Column in dataframe that contains the class/label\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical'  # Change this if not a multiclass classification\n    )\n\n# Create datasets for training, validation, and testing\ntrain_dataset = df_to_dataset(train_df, train_datagen, train_dir)\nvalidation_dataset = df_to_dataset(validate_df, validation_datagen, validation_dir)\n\n# Load the MobileNetV2 model, pretrained on ImageNet, without the top layer\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Unfreeze some layers for fine-tuning\nfine_tune_at = 100\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n\n# Create the model\nmodel = Sequential([\n    base_model,\n    # Convert features to vectors\n    tf.keras.layers.GlobalAveragePooling2D(),\n    # Add a dense layer for classification\n    Dense(1024, activation='relu'),\n    # Final layer with softmax activation for multi-class classification\n    Dense(10, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Start with a small portion (e.g., 10%) of the training data\ntrain_subset = train_df.sample(frac=0.6, random_state=42)\ntrain_subset_dataset = df_to_dataset(train_subset, train_datagen, train_dir)\n\n# Callbacks\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n]\n\n# Fine-tune the model\nhistory = model.fit(\n    train_subset_dataset,  # Use the subset of data\n    validation_data=validation_dataset,\n    epochs=2,  # Initially train for fewer epochs for debugging\n    callbacks=callbacks\n)\n\n# Now, fine-tune the model with the whole training dataset\n# Modify the parameters according to your specific needs\n# For example, increase the number of epochs and adjust the learning rate\nhistory = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=3,  # Train for more epochs for fine-tuning\n    callbacks=callbacks\n)\n\nvalidation_loss, validation_accuracy = model.evaluate(validation_dataset)\nprint(f'Validation Loss: {validation_loss}')\nprint(f'Validation Accuracy: {validation_accuracy}')\n\n# Testing\ntest_dataset = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=test_dir,\n    x_col='imageFile',  # Make sure this column name matches your test_df column name for filenames\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=None,  # No labels\n    shuffle=False\n)\npredictions = model.predict(test_dataset)\npredicted_class_indices = np.argmax(predictions, axis=1)\n\n# Save predictions to a CSV file\nsubmission_df = pd.DataFrame({'uniqueID': test_df['uniqueID'], 'classID': predicted_class_indices})\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T16:01:50.868152Z","iopub.execute_input":"2024-03-31T16:01:50.868480Z","iopub.status.idle":"2024-03-31T18:09:49.075833Z","shell.execute_reply.started":"2024-03-31T16:01:50.868453Z","shell.execute_reply":"2024-03-31T18:09:49.074229Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-31 16:01:53.460573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-31 16:01:53.460674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-31 16:01:53.579433: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 81946 validated image filenames belonging to 10 classes.\nFound 10244 validated image filenames belonging to 10 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nFound 49168 validated image filenames belonging to 10 classes.\nEpoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/1537\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:16:13\u001b[0m 31s/step - accuracy: 0.1875 - loss: 2.3392","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1711901115.254257      81 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1242s\u001b[0m 788ms/step - accuracy: 0.8605 - loss: 0.4276 - val_accuracy: 0.9109 - val_loss: 0.3110\nEpoch 2/2\n\u001b[1m1537/1537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m845s\u001b[0m 548ms/step - accuracy: 0.9492 - loss: 0.1487 - val_accuracy: 0.9406 - val_loss: 0.1814\nRestoring model weights from the end of the best epoch: 2.\nEpoch 1/3\n\u001b[1m2561/2561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1642s\u001b[0m 639ms/step - accuracy: 0.9533 - loss: 0.1320 - val_accuracy: 0.9662 - val_loss: 0.1062\nEpoch 2/3\n\u001b[1m2561/2561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1669s\u001b[0m 650ms/step - accuracy: 0.9639 - loss: 0.1028 - val_accuracy: 0.9552 - val_loss: 0.1486\nEpoch 3/3\n\u001b[1m2561/2561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1565s\u001b[0m 610ms/step - accuracy: 0.9674 - loss: 0.0911 - val_accuracy: 0.9638 - val_loss: 0.1297\nRestoring model weights from the end of the best epoch: 1.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 254ms/step - accuracy: 0.9670 - loss: 0.1024\nValidation Loss: 0.10727931559085846\nValidation Accuracy: 0.9662241339683533\nFound 30690 validated image filenames.\n\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 417ms/step\n","output_type":"stream"}]}]}